# Manual de Usuario - Red Neuronal
## Proyecto Final CS2013 ProgramaciÃ³n III

## DescripciÃ³n
Este proyecto implementa una **red neuronal multicapa completa desde cero** en C++, utilizando una librerÃ­a de tensores personalizada y un sistema de carga/procesamiento de datos CSV para casos de uso reales.

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ§® LibrerÃ­a de Tensores Avanzada
- **Soporte completo para tensores N-dimensionales**
- **Operaciones matemÃ¡ticas optimizadas** (+, -, *, /)
- **MultiplicaciÃ³n matricial eficiente** con validaciÃ³n de dimensiones
- **TransposiciÃ³n y reshape** de tensores
- **Broadcasting inteligente** para operaciones elemento a elemento
- **IndexaciÃ³n multidimensional** con verificaciÃ³n de bounds
- **InicializaciÃ³n Xavier/He** para pesos de red neuronal

### ğŸ§  Red Neuronal Completa
- **Capas densas (fully connected)** con inicializaciÃ³n configurable
- **Funciones de activaciÃ³n**: ReLU, Sigmoid, Tanh
- **Funciones de pÃ©rdida**: MSE (Mean Squared Error), BCE (Binary Cross-Entropy)
- **Optimizadores avanzados**: SGD, Adam con momentum
- **Entrenamiento por lotes** con progreso en tiempo real
- **EvaluaciÃ³n de precisiÃ³n** automÃ¡tica
- **Soporte para datasets personalizados**

### ğŸ“Š Sistema CSV Integrado
- **Carga automÃ¡tica de datasets** desde archivos CSV
- **GeneraciÃ³n de predicciones** en formato CSV
- **ComparaciÃ³n detallada** entre valores esperados y predicciones
- **Workflow completo**: Input â†’ Entrenamiento â†’ Output â†’ AnÃ¡lisis

## ğŸ› ï¸ InstalaciÃ³n y CompilaciÃ³n

### ğŸ“‹ Requisitos del Sistema
- **CMake 3.18 o superior**
- **Compilador C++17 compatible:**
  - GCC 11+ (Linux/Windows)
  - MSVC 2019+ (Windows)
  - Clang 12+ (macOS/Linux)
- **Git** (para clonar el repositorio)

### ğŸªŸ CompilaciÃ³n en Windows (Recomendado)

#### Paso 1: Preparar el entorno
```powershell
# Navegar al directorio del proyecto
cd e:\projecto-final-null\proyecto-final

# Crear directorio de build (si no existe)
mkdir build
cd build
```

#### Paso 2: Configurar con CMake
```powershell
# Configurar el proyecto
cmake ..
```

#### Paso 3: Compilar
```powershell
# Compilar en modo Debug (recomendado para desarrollo)
cmake --build . --config Debug

# O compilar en modo Release (optimizado)
cmake --build . --config Release
```

#### Paso 4: Ejecutar el programa
```powershell
# Ejecutar el demo principal (desde directorio build)
.\bin\Debug\neural_net_demo.exe

# O en modo Release
.\bin\Release\neural_net_demo.exe
```

### ğŸ§ CompilaciÃ³n en Linux/macOS

```bash
# Navegar al proyecto
cd proyecto-final

# Crear y entrar al directorio build
mkdir build && cd build

# Configurar y compilar
cmake ..
make -j$(nproc)

# Ejecutar
./bin/neural_net_demo
```

## ğŸ® Demos Incluidos

El programa incluye **4 demos completos** que demuestran todas las capacidades del sistema:

### 1ï¸âƒ£ **Demo: Tensor Operations**
- Demuestra operaciones bÃ¡sicas con tensores
- MultiplicaciÃ³n matricial, transposiciÃ³n
- Operaciones elemento a elemento
- **PropÃ³sito**: Verificar que la librerÃ­a de tensores funciona correctamente

### 2ï¸âƒ£ **Demo: XOR Problem (usando CSV)**
- Resuelve el problema XOR clÃ¡sico
- **Carga datos desde `input_data.csv`**
- Entrena red neuronal 2â†’4â†’1 con **1000 Ã©pocas**
- **PrecisiÃ³n esperada**: ~100%
- **Tiempo**: ~80-100ms

### 3ï¸âƒ£ **Demo: Circle Classification (usando CSV)**
- ClasificaciÃ³n binaria con el mismo dataset CSV
- Red neuronal 2â†’4â†’1 con **1000 Ã©pocas**
- Muestra progreso de entrenamiento detallado
- **PropÃ³sito**: Demostrar versatilidad del mismo dataset

### 4ï¸âƒ£ **Demo: CSV Workflow Completo**
- **Flujo realista completo**: Input â†’ Entrenamiento â†’ Output
- **Lee**: `input_data.csv` (datos de entrada)
- **Entrena**: Red neuronal 2â†’6â†’1 con **1000 Ã©pocas**
- **Genera**:
  - `output_predictions.csv` (predicciones)
  - `comparison_results.csv` (comparaciÃ³n detallada)
- **EvalÃºa**: PrecisiÃ³n del modelo

## ğŸ“ Archivos CSV del Sistema

### ğŸ“¥ **Input: `input_data.csv`**
```csv
feature_1,feature_2,label
0.1,0.2,1
0.8,0.9,0
0.3,0.1,1
...
```
- **UbicaciÃ³n**: RaÃ­z del proyecto
- **Formato**: 10 muestras, 2 caracterÃ­sticas, 1 etiqueta binaria
- **Usado por**: Todos los demos (datasets unificado)

### ğŸ“¤ **Output: `output_predictions.csv`**
```csv
sample_id,prediction
sample_0,0.954554
sample_1,0.00557967
sample_2,0.980913
...
```
- **UbicaciÃ³n**: RaÃ­z del proyecto
- **Contenido**: Predicciones reales de la red neuronal entrenada

### ğŸ“Š **Analysis: `comparison_results.csv`**
```csv
sample_id,feature_1,feature_2,expected,predicted,difference,correct
sample_0,0.1,0.2,1.0,0.954554,0.045446,1
sample_1,0.8,0.9,0.0,0.00557967,0.00557967,1
...
```
- **UbicaciÃ³n**: RaÃ­z del proyecto
- **Contenido**: AnÃ¡lisis detallado de predicciones vs valores esperados

## ğŸ’» Ejemplos de CÃ³digo

### 1ï¸âƒ£ **Crear y Manipular Tensores**

```cpp
#include "src/tensor.h"
using namespace utec::algebra;

// Crear tensor 2D (matriz 3x3)
Tensor<float, 2> matrix(3, 3);

// Inicializar con valores
matrix = {1, 2, 3, 4, 5, 6, 7, 8, 9};

// Operaciones bÃ¡sicas
auto doubled = matrix * 2.0f;              // MultiplicaciÃ³n por escalar
auto transposed = matrix.transpose();       // TransposiciÃ³n
auto sum_result = matrix + doubled;         // Suma elemento a elemento

// MultiplicaciÃ³n matricial
Tensor<float, 2> other(3, 2);
other = {1, 2, 3, 4, 5, 6};
auto product = matrix.matmul(other);        // Resultado: 3x2

// Acceso a elementos
float value = matrix(1, 2);                 // Fila 1, Columna 2
std::cout << "Matrix:\n" << matrix;         // ImpresiÃ³n formateada
```

### 2ï¸âƒ£ **Crear Red Neuronal Completa**

```cpp
#include "src/neural_network.h"
using namespace utec::neural_network;
using namespace utec::data;

// Crear red neuronal
NeuralNetwork<float> network;

// Agregar capas con inicializaciÃ³n Xavier
network.add_layer(std::make_unique<Dense<float>>(
    2, 4,                                    // 2 entradas â†’ 4 neuronas
    Initializers<float>::xavier_init,        // Pesos Xavier
    Initializers<float>::zero_init           // Bias en cero
));
network.add_layer(std::make_unique<ReLU<float>>());
network.add_layer(std::make_unique<Dense<float>>(4, 1, 
    Initializers<float>::xavier_init, 
    Initializers<float>::zero_init
));
network.add_layer(std::make_unique<Sigmoid<float>>());

// Datos de entrenamiento (problema XOR)
Tensor<float, 2> X(4, 2);
X = {0, 0,    // XOR: [0,0] â†’ 0
     0, 1,    //      [0,1] â†’ 1  
     1, 0,    //      [1,0] â†’ 1
     1, 1};   //      [1,1] â†’ 0

Tensor<float, 2> Y(4, 1);
Y = {0, 1, 1, 0};

// Entrenar la red
network.train<MSELoss, SGD>(
    X, Y,           // Datos de entrada y salida
    1000,           // Ã‰pocas
    4,              // TamaÃ±o de lote
    0.1f,           // Tasa de aprendizaje
    true            // Mostrar progreso
);

// Hacer predicciones
auto predictions = network.predict(X);
std::cout << "Predicciones:\n" << predictions;

// Evaluar precisiÃ³n
float accuracy = network.evaluate_accuracy(X, Y);
std::cout << "PrecisiÃ³n: " << (accuracy * 100) << "%\n";
```

### 3ï¸âƒ£ **Cargar Datos desde CSV**

```cpp
#include "src/csv_loader.h"
using namespace utec::data;

// Cargar dataset desde CSV
auto dataset = CSVLoader<float>::load_csv(
    "input_data.csv",    // Archivo
    true,                // Tiene header
    ',',                 // Delimitador
    -1                   // Ãšltima columna como label
);

std::cout << "Muestras: " << dataset.X.shape()[0] << std::endl;
std::cout << "CaracterÃ­sticas: " << dataset.X.shape()[1] << std::endl;

// Entrenar con datos CSV
NeuralNetwork<float> network;
// ... configurar capas ...
network.train<BCELoss, SGD>(dataset.X, dataset.Y, 1000, 10, 0.01f);

// Generar predicciones
auto predictions = network.predict(dataset.X);

// Guardar resultados
CSVLoader<float>::save_predictions("output.csv", predictions);
CSVLoader<float>::save_comparison("comparison.csv", 
    dataset.X, dataset.Y, predictions,
    dataset.feature_names, dataset.label_names
);
```

### 4ï¸âƒ£ **Configurar Diferentes Optimizadores**

```cpp
// SGD (Stochastic Gradient Descent)
network.train<MSELoss, SGD>(X, Y, epochs, batch_size, learning_rate);

// Adam (con momentum adaptativo)
network.train<BCELoss, Adam>(X, Y, epochs, batch_size, learning_rate);

// Diferentes funciones de pÃ©rdida
network.train<MSELoss, SGD>(X, Y, 1000, 4, 0.1f);     // Para regresiÃ³n
network.train<BCELoss, Adam>(X, Y, 1000, 4, 0.001f);  // Para clasificaciÃ³n binaria
```

## ğŸ—ï¸ Arquitectura del Proyecto

```
e:\projecto-final-null\proyecto-final/
â”œâ”€â”€ ğŸ“ src/                           # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ ğŸ§® tensor.h                   # LibrerÃ­a de tensores N-dimensionales
â”‚   â”œâ”€â”€ ğŸ§  neural_network.h           # Clase principal de red neuronal
â”‚   â”œâ”€â”€ ğŸ“Š csv_loader.h               # Sistema de carga/guardado CSV
â”‚   â”œâ”€â”€ ğŸ“ layers/                    # Capas de la red neuronal
â”‚   â”‚   â”œâ”€â”€ ğŸ”— nn_interfaces.h        # Interfaces base (Layer, etc.)
â”‚   â”‚   â”œâ”€â”€ ğŸ”¢ nn_dense.h             # Capa densa (fully connected)
â”‚   â”‚   â”œâ”€â”€ âš¡ nn_activation.h        # Funciones de activaciÃ³n
â”‚   â”‚   â””â”€â”€ ğŸ“‰ nn_loss.h              # Funciones de pÃ©rdida
â”‚   â””â”€â”€ ğŸ“ optimizers/                # Algoritmos de optimizaciÃ³n
â”‚       â””â”€â”€ ğŸ¯ nn_optimizer.h         # SGD, Adam, etc.
â”œâ”€â”€ ğŸ“ build/                         # Archivos de compilaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“ bin/Debug/                 # Ejecutables Debug
â”‚   â””â”€â”€ ğŸ“ bin/Release/               # Ejecutables Release
â”œâ”€â”€ ğŸ“ tests/                         # Pruebas unitarias
â”‚   â”œâ”€â”€ ğŸ§ª test_tensor.cpp            # Tests de tensores
â”‚   â””â”€â”€ ğŸ§ª test_neural_network.cpp    # Tests de red neuronal
â”œâ”€â”€ ğŸ“ docs/                          # DocumentaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“– manual_usuario.md          # Este manual
â”‚   â””â”€â”€ ğŸ“š investigacion_teorica.md   # Fundamentos teÃ³ricos
â”œâ”€â”€ ğŸš€ main.cpp                       # Demo principal (4 demos)
â”œâ”€â”€ âš™ï¸ CMakeLists.txt                 # ConfiguraciÃ³n de build
â”œâ”€â”€ ğŸ“¥ input_data.csv                 # Dataset de entrada
â”œâ”€â”€ ğŸ“¤ output_predictions.csv         # Predicciones generadas (se crea luego de ejecutar)
â””â”€â”€ ğŸ“Š comparison_results.csv         # AnÃ¡lisis de resultados (se crea luego de ejecutar)
```

### ğŸ”§ Componentes Principales

#### **1. Tensor Engine (`tensor.h`)**
- **Motor de cÃ¡lculo matricial** de alto rendimiento
- **Soporte N-dimensional** con verificaciÃ³n de tipos
- **Operaciones vectorizadas** para eficiencia

#### **2. Neural Network Core (`neural_network.h`)**
- **Arquitectura modular** con capas intercambiables
- **Forward/Backward propagation** optimizado
- **Training loop** con mÃ©tricas en tiempo real

#### **3. CSV Data Pipeline (`csv_loader.h`)**
- **Parser CSV robusto** con manejo de errores
- **ConversiÃ³n automÃ¡tica** a tensores
- **Export de resultados** en mÃºltiples formatos

#### **4. Layer System (`layers/`)**
- **Interface uniforme** para todas las capas
- **Dense layers** con inicializaciÃ³n configurable
- **Activation functions** diferenciables

#### **5. Optimization Engine (`optimizers/`)**
- **SGD** con momentum opcional
- **Adam** con decay adaptativo
- **Extensible** para nuevos optimizadores

## ğŸ§ª Testing y ValidaciÃ³n

### ğŸƒâ€â™‚ï¸ Ejecutar Tests (Opcional)

```powershell
# Compilar con tests habilitados
cmake .. -DBUILD_TESTS=ON
cmake --build . --config Debug

# Ejecutar tests individuales
.\test_tensor.exe
.\test_neural_network.exe
```

### âœ… VerificaciÃ³n de Funcionamiento

#### **Indicadores de Ã‰xito:**
1. **CompilaciÃ³n exitosa** sin errores ni warnings
2. **Todos los demos ejecutan** sin excepciones
3. **Archivos CSV generados** en la raÃ­z del proyecto
4. **PrecisiÃ³n del XOR â‰¥ 95%** (debe ser ~100%)
5. **Tiempos de entrenamiento < 200ms** por demo

#### **Salida Esperada:**
```
========================================
   Neural Network Demo - Proyecto Final
   CS2013 ProgramaciÃ³n III
========================================

=== Demo: Tensor Operations ===
Matrix A (2x3): ...
âœ… Operaciones tensoriales correctas

=== Demo: XOR Problem (using input_data.csv) ===
Loaded dataset from CSV: 10 samples, 2 features
Training network with 1000 epochs...
Accuracy: 100%
âœ… XOR resuelto perfectamente

=== Demo: Circle Classification (using input_data.csv) ===
Training time: 76 ms
Final accuracy: 50-90%
âœ… ClasificaciÃ³n completada

=== Demo: CSV Workflow ===
âœ… Saved output_predictions.csv
âœ… Saved comparison_results.csv
ğŸ“Š Model accuracy: 100%
âœ… CSV workflow completed successfully!

========================================
   All demos completed successfully!
========================================
```

## ğŸš¨ SoluciÃ³n de Problemas

### âŒ **Error: "cmake: command not found"**
**SoluciÃ³n**: Instalar CMake desde https://cmake.org/download/

### âŒ **Error: "Compilador C++17 no encontrado"**
**SoluciÃ³n**: 
- Windows: Instalar Visual Studio 2019+
- Linux: `sudo apt install g++-11`

### âŒ **Error: "neural_net_demo.exe no encontrado"**
**Verificar**:
```powershell
dir bin\Debug\       # Debe mostrar neural_net_demo.exe
```

### âŒ **Error: "input_data.csv not found"**
**Verificar**:
```powershell
dir ..\*.csv         # Desde directorio build
```

### âŒ **Warning: PrecisiÃ³n baja (<50%)**
**Posibles causas**:
- Dataset muy pequeÃ±o (normal con 10 muestras)
- Learning rate muy alto/bajo
- Pocas Ã©pocas de entrenamiento

## ğŸ“Š MÃ©tricas de Rendimiento

### â±ï¸ **Tiempos Esperados** (Windows, CPU moderno):
- **Demo Tensor Operations**: < 5ms
- **Demo XOR Problem**: 80-100ms
- **Demo Circle Classification**: 70-80ms  
- **Demo CSV Workflow**: 50-100ms
- **Total**: < 300ms

### ğŸ¯ **PrecisiÃ³n Esperada**:
- **XOR Problem**: 95-100%
- **Circle Classification**: 50-90% (depende del dataset)
- **CSV Workflow**: 80-100%

### ğŸ’¾ **Uso de Memoria**: < 50MB
### ğŸ—ƒï¸ **Archivos Generados**: 3 CSV (~1-5KB cada uno)

## âš ï¸ Limitaciones Conocidas

### ğŸš€ **Rendimiento**
- **ImplementaciÃ³n didÃ¡ctica**: Optimizada para claridad del cÃ³digo, no velocidad mÃ¡xima
- **CPU solo**: No incluye aceleraciÃ³n GPU (CUDA/OpenCL)
- **Threading**: Sin paralelizaciÃ³n explÃ­cita del entrenamiento

### ğŸ’¾ **Memoria**
- **Datasets pequeÃ±os**: Optimizado para datasets de demostraciÃ³n (<1000 muestras)
- **Carga completa**: Todos los datos se cargan en memoria
- **Sin streaming**: No hay soporte para datasets que no quepan en RAM

### ğŸ”§ **Funcionalidad**
- **Capas limitadas**: Solo Dense + Activaciones bÃ¡sicas
- **Formatos**: Solo CSV para datos, no hay JSON/XML/binario
- **Persistencia**: No incluye guardado/carga de modelos entrenados
- **RegularizaciÃ³n**: Sin Dropout, Batch Normalization, etc.

## ğŸš€ Extensiones Futuras

### ğŸ§  **MÃ¡s Tipos de Capas**
```cpp
// Propuestas para futuras versiones:
network.add_layer(std::make_unique<Convolutional2D<float>>(32, 3, 3));
network.add_layer(std::make_unique<LSTM<float>>(128));
network.add_layer(std::make_unique<Dropout<float>>(0.5f));
network.add_layer(std::make_unique<BatchNormalization<float>>());
```

### âš¡ **Optimizaciones de Rendimiento**
- **BLAS integration**: Usar librerÃ­as optimizadas (Intel MKL, OpenBLAS)
- **SIMD**: VectorizaciÃ³n explÃ­cita con instrucciones AVX/SSE
- **GPU support**: ImplementaciÃ³n CUDA para entrenamiento masivo
- **Parallel training**: Multi-threading para lotes grandes

### ğŸ“Š **MÃ¡s MÃ©tricas y Funcionalidades**
```cpp
// MÃ©tricas avanzadas
float f1_score = network.evaluate_f1(X, Y);
float precision = network.evaluate_precision(X, Y);
float recall = network.evaluate_recall(X, Y);

// Callbacks de entrenamiento
network.add_callback(std::make_unique<EarlyStopping>(patience=10));
network.add_callback(std::make_unique<LearningRateScheduler>());
```

### ğŸ’¾ **Persistencia de Modelos**
```cpp
// Guardar modelo entrenado
network.save("mi_modelo.nn");

// Cargar modelo previamente entrenado
auto network = NeuralNetwork<float>::load("mi_modelo.nn");
```

### ğŸŒ **Soporte de Formatos**
- **JSON/XML**: Para configuraciÃ³n de arquitecturas
- **HDF5/NPZ**: Para datasets cientÃ­ficos grandes
- **ONNX**: Para interoperabilidad con otros frameworks

## ğŸ‘¥ InformaciÃ³n del Proyecto

### ğŸ“š **Curso**: CS2013 ProgramaciÃ³n III
### ğŸ¯ **Objetivo**: ImplementaciÃ³n completa de red neuronal desde cero
### ğŸ’» **Lenguaje**: C++17 moderno
### ğŸ› ï¸ **Build System**: CMake 3.18+
### ğŸ“… **VersiÃ³n**: 2025.01 (Proyecto Final)

### ğŸ”— **Componentes Implementados**:
- âœ… **LibrerÃ­a de Tensores N-dimensionales**
- âœ… **Red Neuronal Multicapa**
- âœ… **Sistema de OptimizaciÃ³n (SGD/Adam)**
- âœ… **Pipeline CSV Completo**
- âœ… **4 Demos Funcionales**
- âœ… **DocumentaciÃ³n Completa**

---

## ğŸ“ Soporte

Si encuentras problemas durante la compilaciÃ³n o ejecuciÃ³n:

1. **Verificar requisitos**: CMake 3.18+, C++17
2. **Limpiar build**: `rm -rf build && mkdir build`
3. **Verificar archivos CSV**: Deben estar en la raÃ­z del proyecto
4. **Revisar logs de compilaciÃ³n**: Buscar errores especÃ­ficos

**Â¡El proyecto estÃ¡ diseÃ±ado para funcionar out-of-the-box en sistemas Windows modernos!** ğŸ‰
